{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_experimental.graph_transformers.llm import LLMGraphTransformer\n",
    "from langchain_openai import AzureChatOpenAI, ChatOpenAI\n",
    "from langchain_text_splitters.character import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deepseek\n",
    "# API_KEY = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "# ENDPOINT = \"https://api.deepseek.com\"\n",
    "# MODEL_NAME = \"deepseek-chat\"\n",
    "\n",
    "# Github marketplace\n",
    "# API_KEY = os.getenv(\"GITHUB_MARKETPLACE_API_KEY\")\n",
    "# ENDPOINT = \"https://models.inference.ai.azure.com\"\n",
    "# MODEL_NAME = \"gpt-4o\"\n",
    "\n",
    "# Cloudflare Worker AI\n",
    "API_KEY = os.getenv(\"CLOUDFLARE_WORKER_AI_API_KEY\")\n",
    "ACCOUNT_ID = os.getenv(\"CLOUDFLARE_WORKER_AI_ACCOUNT_ID\")\n",
    "ENDPOINT = f\"https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/v1\"\n",
    "MODEL_NAME = \"@cf/meta/llama-3.1-8b-instruct\"\n",
    "\n",
    "os.environ[\"SSL_CERT_FILE\"] = os.getenv(\"REQUESTS_CA_BUNDLE\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=ENDPOINT,\n",
    "    model=MODEL_NAME,\n",
    "    api_key=API_KEY,\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the document\n",
    "loaded_documents = TextLoader(file_path=\"imdbtop3.txt\").load()\n",
    "\n",
    "# Split the document into chunks\n",
    "documents_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=300)\n",
    "splitted_documents = documents_splitter.split_documents(documents=loaded_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform documents into graph-based documents using a LLM\n",
    "# Set allowed nodes and relationships\n",
    "llm_graph_transformer = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "# Convert the splitted documents into graph documents\n",
    "graph_documents = llm_graph_transformer.convert_to_graph_documents(splitted_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEO4J connection\n",
    "neo4j_uri = \"bolt://localhost:7183\"\n",
    "neo4j_user = \"neo4j\"\n",
    "neo4j_password = \"langchain\"\n",
    "\n",
    "graph = Neo4jGraph(url=neo4j_uri, username=neo4j_user, password=neo4j_password)\n",
    "graph.add_graph_documents(graph_documents, baseEntityLabel=False, include_source=False)\n",
    "\n",
    "# MATCH (n) DETACH DELETE n;\n",
    "# MATCH (n)-[r]->(m) RETURN n, r, m;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph\n",
    "from neo4j import GraphDatabase\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "\n",
    "# NEO4J connection\n",
    "neo4j_uri = \"bolt://localhost:7183\"\n",
    "neo4j_user = \"neo4j\"\n",
    "neo4j_password = \"langchain\"\n",
    "\n",
    "def showGraph():\n",
    "    driver = GraphDatabase.driver(uri = neo4j_uri, auth = (neo4j_user, neo4j_password))\n",
    "    session = driver.session()\n",
    "    widget = GraphWidget(graph = session.run(\"MATCH (n)-[r]->(m) RETURN n, r, m;\").graph())\n",
    "    widget.node_label_mapping = 'id'\n",
    "    return widget\n",
    "\n",
    "showGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query NEO4J with natural language\n",
    "\n",
    "graph.refresh_schema()\n",
    "#  print(graph.schema)\n",
    "\n",
    "neo4j_query = GraphCypherQAChain.from_llm(\n",
    "    llm=llm,\n",
    "    graph=graph,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True,\n",
    ")\n",
    "\n",
    "message = neo4j_query.invoke({\"query\": \"Who acted in The Shawshank Redemption, and the according role\"})\n",
    "print(message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
